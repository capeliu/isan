<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Isan by zhangkaixu</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
    <script src="javascripts/main.js"></script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  </head>
  <body>

      <header>
        <h1>Isan</h1>
        <p>Chinese processing</p>
      </header>

      <div id="banner">
        <span id="logo"></span>

        <a href="https://github.com/zhangkaixu/isan" class="button fork"><strong>View On GitHub</strong></a>
        <div class="downloads">
          <span>Downloads:</span>
          <ul>
            <li><a href="https://github.com/zhangkaixu/isan/zipball/master" class="button">ZIP</a></li>
            <li><a href="https://github.com/zhangkaixu/isan/tarball/master" class="button">TAR</a></li>
          </ul>
        </div>
      </div><!-- end banner -->

    <div class="wrapper">
      <nav>
        <ul></ul>
      </nav>
      <section>
        <h1>isan</h1>

<blockquote>
<p>“举一隅不以三隅反，则不复也” ——《论语·述而》</p>
</blockquote>

<p>一个数据驱动的中文处理**实验环境**，可进行*中文分词*和*依存句法分析*等任务。作者<a href="http://weibo.com/zhangkaixu">张开旭</a>。</p>

<p>特点</p>

<ul>
<li>速度**慢**，不为速度牺牲性能，同时保证算法的各个组件的代码容易修改，但理论上保持<code>O(n)</code>的时间复杂度。</li>
<li>效果**差**，本系统专为实验使用，目标并非实用分词工具，处理真实文本效果并不理想。但可用于设计实用分词系统。</li>
<li>使用**难**，虽然不太实用，但有很多“手动功能”，可以通过理解并修改源代码来完成算法和设置的充分修改。</li>
</ul><h1>Run</h1>

<h2>Getting started</h2>

<p>在此以Ubuntu操作系统为例，介绍如何安装和使用**isan**。</p>

<p>首先，需要安装必要的软件包，包括gcc，make，Python3，Python3-dev和git，在命令行下安装：</p>

<pre><code>sudo apt-get install gcc
sudo apt-get install make
sudo apt-get install python3
sudo apt-get install python3-dev
sudo apt-get install git
</code></pre>

<p>选好路径，使用git下载**isan**源代码，编译。</p>

<pre><code>git clone https://github.com/zhangkaixu/isan.git
cd isan
make
</code></pre>

<p>下载一个可供实验用的SIGHAN05中文分词语料库。</p>

<pre><code>wget http://www.sighan.org/bakeoff2005/data/icwb2-data.rar
sudo apt-get install unrar
mkdir sighan05
unrar e icwb2-data.rar sighan05
</code></pre>

<p>试着训练和测试，看看程序是否安装正确。</p>

<pre><code>./cws.sh test.bin --train sighan05/msr_test_gold.utf8
./cws.sh test.bin --test sighan05/msr_test_gold.utf8
</code></pre>

<p>如果以上一切顺利，将会看到测试结果能有0.99以上的F1值。接下来就可以试着真枪实弹地来一次，在MSR的训练集上迭代20次训练模型，每次迭代都将测试集作为开发集检查一下模型性能。</p>

<pre><code>./cws.sh test.bin --train sighan05/msr_training.utf8 --iteration=20 --dev sighan05/msr_test_gold.utf8 --beam_width=16
</code></pre>

<p>可以看到最后效果保持在0.973左右，一个还算可以的baseline吧？</p>

<p>那么只要对代码的某些地方进行进一步的修改，就可能有比baseline更好的分词模型了。</p>

<h2>Command line</h2>

<p>以中文分词为例，命令行用法如下：</p>

<pre><code>./cws.sh model_file [--train training_file] [--test test_file] [--dev dev_file]
    [--iteration iter] [--beam_width w]
</code></pre>

<p>其中：</p>

<ul>
<li>
<code>model_file</code> 是用以存储模型参数的文件</li>
<li>
<code>training_file</code> 如果给出，会使用该文件训练模型</li>
<li>
<code>dev_file</code> 如果给出，会在每次训练迭代之后在<code>dev_file</code>上测试模型效果</li>
<li>
<code>test_file</code> 如果给出，会使用已有模型或新训练的模型在该文件上进行测试</li>
<li>如果 <code>training_file</code> 和 <code>test_file</code> 均未给出，则对标准输入流中的文本进行分词，输出结果到标准输出流</li>
<li>
<code>iter</code> 用来指定训练时的迭代次数</li>
<li>
<code>w</code> 用来指定柱搜索解码中的搜索宽度（柱宽度）</li>
</ul><p>词性标注的基本命令行用法相同，只需要将<code>cws.sh</code>替换为<code>tag.py</code>（当然部分功能尚未实现）。</p>

<h2>Input &amp; output</h2>

<p>每个句子一行</p>

<ul>
<li>原始句子 <code>材料利用率高。</code>
</li>
<li>分词结果 <code>材料 利用率 高 。</code>
</li>
<li>词性标注结果 <code>材料_NN 利用率_NN 高_VA 。_PU</code>
</li>
</ul><p>例如在分词<code>./cws.sh</code>命令中，<code>training_file</code> 、 <code>dev_file</code>、 <code>test_file</code> 以及预测阶段的输出的格式均是使用的分词结果格式， 预测阶段的输入格式是原始句子格式。</p>

<h1>Architecture</h1>

<p>现以分词模型为例，介绍程序架构。</p>

<h2>The program</h2>

<p>首先看看<code>./cws.sh</code>文件，其包含了模型的三个组成部分：</p>

<pre><code>./isan.py \
    --model isan.common.perceptrons.Model \
    --decoder isan.common.decoder.DFA \
    --task isan.tagging.cws.Task \
    $*
</code></pre>

<p>首先是<code>--task</code>，包含了分词相关的所有代码，仔细阅读<a href="https://github.com/zhangkaixu/isan/blob/master/isan/tagging/default_segger_c.py">源代码</a>中的所有内容，修改其中的代码，就能DIY出自己的分词模型。</p>

<p>其次是<code>--decoder</code>，是一个解码器，与具体的任务无关。分词使用的是基于状态转移的<code>DFA</code>解码器，也就是一个维特比解码器，相同解码器也可完成词性标注等任务。此外模型的特征权重也由Searcher管理。</p>

<p>最后是<code>--model</code>，是控制模型学习、预测过程的，与具体的任务和解码器均无关。该例子中使用的是平均感知器算法进行模型的学习和预测。</p>

<h2>Decoding</h2>

<p>解码就是根据**输入**搜索得到**输出**的过程。</p>

<h3>Actions</h3>

<p><strong>isan</strong>是这样建模的。首先定义一个**动作**的集合，解码过程就是根据输入，得到一个动作序列，然后根据输入与动作序列，就能唯一确定输出。因此解码的过程就是根据输入得到动作序列的过程。</p>

<p>在分词例子中，动作有两种，即 <em>分</em> 与 <em>断</em> ，一个有<code>n</code>个字的输入，对应的动作序列中有<code>n+1</code>个动作，分别表示各个字边界是分还是断。</p>

<h3>Status</h3>

<p>下面的问题是如何依次确定动作序列中每个位置具体的动作。首先引入**状态**这一概念，有一个初始状态，一个状态根据不同的动作转移到下一个不同的状态。最后到终止状态。**isan**根据当前状态确定下一个动作哪个好哪个不好。</p>

<h3>Features</h3>

<p>具体地，由状态和输入可生成每个状态的特征，每个特征-动作二元组对应一个权重。那么对于一个动作，一个状态的<code>k</code>个特征就有<code>k</code>个权重，它们线性相加就是一个分数，对应着这个动作的优劣。</p>

<p>接下来，回到最开始的解码中确定动作序列的问题上，一个动作序列的的好坏，由序列中每个动作的分数相加得到。解码就是尽量找到分数最高的动作序列，以此生成输出。</p>
      </section>
      <footer>
        <p>Project maintained by <a href="https://github.com/zhangkaixu">zhangkaixu</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="http://twitter.com/#!/michigangraham">mattgraham</a></small></p>
      </footer>
    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
              <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-33732606-2");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>

  </body>
</html>